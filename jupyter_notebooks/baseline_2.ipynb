{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4XTgGoU9nrg",
        "colab_type": "code",
        "outputId": "177b0414-d75a-4431-9829-5883ac5e0492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIYKLwd8V7xQ",
        "colab_type": "code",
        "outputId": "ef78d5ab-0b08-4f3c-d3bb-aa582452bd28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "\n",
        "import torch\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "from pathlib import Path\n",
        "from collections import defaultdict"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.13.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.16.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.13->boto3->pytorch_pretrained_bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPanQA1xdCas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TECHNIQUES = [\n",
        "    'No', 'Whataboutism', 'Thought-terminating_Cliches', 'Straw_Men', 'Slogans', 'Repetition',\n",
        "    'Reductio_ad_hitlerum', 'Red_Herring', 'Obfuscation,Intentional_Vagueness,Confusion',\n",
        "    'Name_Calling,Labeling', 'Loaded_Language', 'Flag-Waving', 'Exaggeration,Minimisation',\n",
        "    'Doubt', 'Causal_Oversimplification', 'Black-and-White_Fallacy', 'Bandwagon',\n",
        "    'Appeal_to_fear-prejudice', 'Appeal_to_Authority'\n",
        "]\n",
        "\n",
        "ARTICLE = 7\n",
        "EMBEDDING_SIZE = 768"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9CbDwCsI7wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/My Drive/bert/vocab.txt', do_lower_case=False)\n",
        "model = BertModel.from_pretrained('/content/drive/My Drive/bert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7zAYpsTYSbM",
        "colab_type": "code",
        "outputId": "b1515021-8d5e-43ba-98bf-446d0cc3fa87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "tokenizer.tokenize(\"\"\"Почти треть неплательщиков по кредитам заявили о потере работы.\n",
        "А так?\"\"\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Почти',\n",
              " 'треть',\n",
              " 'неплат',\n",
              " '##ель',\n",
              " '##щиков',\n",
              " 'по',\n",
              " 'кредитам',\n",
              " 'заявили',\n",
              " 'о',\n",
              " 'потере',\n",
              " 'работы',\n",
              " '.',\n",
              " 'А',\n",
              " 'так',\n",
              " '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-29WEKkvheuQ",
        "colab_type": "code",
        "outputId": "021b84ad-09a1-44ea-d731-83942f9c7215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "tokenizer.wordpiece_tokenizer.tokenize(\"Почти треть неплательщиков по кредитам заявили о потере работы\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Почти',\n",
              " 'треть',\n",
              " 'неплат',\n",
              " '##ель',\n",
              " '##щиков',\n",
              " 'по',\n",
              " 'кредитам',\n",
              " 'заявили',\n",
              " 'о',\n",
              " 'потере',\n",
              " 'работы']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAq2JAYwYSwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"Я не понимаю, что происходит. А ты?\"))).unsqueeze(0)  # Batch size 1\n",
        "outputs = model(input_ids)\n",
        "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bmlyy36bI8S",
        "colab_type": "text"
      },
      "source": [
        "#### Make dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "263So5lXaltM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_list(id_, directory):\n",
        "    \"\"\"\n",
        "    Функция, возвращающая список [{}, {}, ..., {Flag-Waving, Bandwagon}, ..., {}, {}].\n",
        "    \"\"\"\n",
        "\n",
        "    lines = []\n",
        "    labels_file = directory.joinpath(f'article{id_}.labels.tsv')\n",
        "    if labels_file.is_file():\n",
        "        with open(labels_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "    with open(directory.joinpath(f'article{id_}.txt'), 'r', encoding='utf-8') as inner_f:\n",
        "        length = len(inner_f.read())\n",
        "    lst = [set() for _ in range(length)]\n",
        "    for line in lines:\n",
        "        id_, technique, left, right = line.split()\n",
        "        id_, left, right = list(map(int, (id_, left, right)))\n",
        "        for i in range(left, right):\n",
        "            lst[i].add(technique)\n",
        "    return lst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aouM1D5nc1lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "techniques_to_ids = {technique: i for i, technique in enumerate(TECHNIQUES)}\n",
        "ids_to_techniques = {i: technique for i, technique in enumerate(TECHNIQUES)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0buD64ojMFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def juxtapose_tokens_with_labels(text, tokenized_text, labels):\n",
        "    new_labels = []\n",
        "    text_index = 0\n",
        "    for token in tokenized_text:\n",
        "        if token != '#':\n",
        "            token = token.replace('#', '').strip()\n",
        "        if token == '[UNK]':\n",
        "            while text_index < len(text) and text[text_index] != ' ':\n",
        "                text_index += 1\n",
        "            new_labels.append(set())\n",
        "            continue\n",
        "        i = 0\n",
        "        while token[i] != text[text_index]:\n",
        "            text_index += 1\n",
        "        cur_labels = set()\n",
        "        while i < len(token) and token[i] == text[text_index]:\n",
        "            cur_labels |= labels[text_index]\n",
        "            i += 1\n",
        "            text_index += 1\n",
        "        new_labels.append(cur_labels)\n",
        "        while text_index < len(text) and text[text_index] == ' ':\n",
        "            text_index += 1\n",
        "    return new_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klI3rwBAall8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(directory):\n",
        "    \"\"\" returns [([__emdeddig 768 nums here__], 2), ...] \"\"\"\n",
        "\n",
        "    result_lst = []\n",
        "    for f in directory.glob('*.txt'):\n",
        "        id_ = int(f.name.split('.')[0][ARTICLE:])\n",
        "\n",
        "\n",
        "        print(f'id: {id_}')\n",
        "\n",
        "        text = f.read_text(encoding='utf-8')\n",
        "        labels = get_list(id_, directory)\n",
        "        assert len(text) == len(labels)\n",
        "\n",
        "        slash_n_indices = [-1] + [i for i, symbol in enumerate(text + '\\n') if symbol == '\\n']\n",
        "        labels = [labels[ix1+1:ix2] for ix1, ix2 in zip(slash_n_indices, slash_n_indices[1:])]\n",
        "\n",
        "        sents = text.split('\\n')\n",
        "        for sent, inner_labels in zip(sents, labels):\n",
        "            assert len(sent) == len(inner_labels)\n",
        "            if not sent.strip():\n",
        "                continue\n",
        "            tokenized_sent = tokenizer.tokenize(sent)\n",
        "            inner_labels = juxtapose_tokens_with_labels(sent, tokenized_sent, inner_labels)\n",
        "            input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(tokenized_sent)).unsqueeze(0)\n",
        "            vectors = model(input_ids)[0][0][0]\n",
        "            assert len(inner_labels) == len(vectors)\n",
        "            for label_set, vector in zip(inner_labels, vectors):\n",
        "                if not label_set:\n",
        "                    result_lst.append((vector, techniques_to_ids['No']))\n",
        "                for label in label_set:\n",
        "                    result_lst.append((vector, techniques_to_ids[label]))\n",
        "    return result_lst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihcCbt46cGvX",
        "colab_type": "code",
        "outputId": "f5468cfc-3cb0-457f-d793-d185eb22c924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "train_lst = get_dataset(Path('/content/drive/My Drive/data/protechn_corpus_eval/train'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id: 59526381559\n",
            "id: 32194915387\n",
            "id: 33748247649\n",
            "id: 31808762171\n",
            "id: 47605119071\n",
            "id: 41105096806\n",
            "id: 36163344507\n",
            "id: 52498183368\n",
            "id: 69294925216\n",
            "id: 39414275139\n",
            "id: 30155268335\n",
            "id: 46988185699\n",
            "id: 83173104362\n",
            "id: 97506920380\n",
            "id: 8359563559\n",
            "id: 95967168572\n",
            "id: 70596768299\n",
            "id: 12402123807\n",
            "id: 73261993887\n",
            "id: 98031283058\n",
            "id: 53367064078\n",
            "id: 88984544092\n",
            "id: 80813611079\n",
            "id: 76806922030\n",
            "id: 34042375985\n",
            "id: 5326402550\n",
            "id: 83366723989\n",
            "id: 3490019195\n",
            "id: 78669648346\n",
            "id: 2966778328\n",
            "id: 62799282082\n",
            "id: 23687061547\n",
            "id: 27152183323\n",
            "id: 59051731723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4AdhIM6GKwf",
        "colab_type": "code",
        "outputId": "d17ebffa-7192-475b-aa24-8b1f2714cf6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "test_lst = get_dataset(Path('/content/drive/My Drive/data/protechn_corpus_eval/test'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id: 36081082999\n",
            "id: 68462833391\n",
            "id: 53424346461\n",
            "id: 96558350001\n",
            "id: 73936725916\n",
            "id: 81020435922\n",
            "id: 7838448925\n",
            "id: 1241238761\n",
            "id: 37505201774\n",
            "id: 33351244185\n",
            "id: 40120334507\n",
            "id: 9894248866\n",
            "id: 86789309327\n",
            "id: 66812338278\n",
            "id: 1173236160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LX9xUa5Iy0K",
        "colab_type": "code",
        "outputId": "f8ec5069-acd6-47b4-d9c8-53f9e5681903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_lst), len(test_lst)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31954, 22102)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9_3KfgCDmFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tmp_lst = [(list(pair[0].detach().numpy()) + [int(pair[1])]) for pair in train_lst]\n",
        "test_tmp_lst = [(list(pair[0].detach().numpy()) + [int(pair[1])]) for pair in test_lst]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBuJ1oMSNb8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('/content/drive/My Drive/data/protechn_corpus_eval/train_lst.json', 'w', encoding='utf-8') as f:\n",
        "#     json.dump(str(train_tmp_lst), f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7APn5-tOG4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('/content/drive/My Drive/data/protechn_corpus_eval/test_lst.json', 'w', encoding='utf-8') as f:\n",
        "#     json.dump(str(test_tmp_lst), f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR3EGIN-D5c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.DataFrame.from_records(train_tmp_lst)\n",
        "test_df = pd.DataFrame.from_records(test_tmp_lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3H4ATEGgzd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpGce2Dhg2_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f41fa680-e59e-42c3-d40d-fd1b53042f29"
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((31954, 769), (22102, 769))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlD3esXjhOlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.head(5000)\n",
        "test_df = test_df.head(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ_Pqff6lN5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = train_df.loc[:, train_df.columns != EMBEDDING_SIZE], train_df[EMBEDDING_SIZE]\n",
        "X_test, y_test = test_df.loc[:, test_df.columns != EMBEDDING_SIZE], test_df[EMBEDDING_SIZE]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9tLUAuyJFC7",
        "colab_type": "code",
        "outputId": "0e067537-10e2-465a-d67d-f0e57757a664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 768), (5000,), (5000, 768), (5000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVxWOEG1alr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_YkXx72alqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"Nearest Neighbors\", \n",
        "names = [\n",
        "    \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
        "    \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "    \"Naive Bayes\", \"QDA\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuxN9yHOamVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [\n",
        "    # KNeighborsClassifier(1),\n",
        "    # SVC(kernel=\"linear\", C=0.025),\n",
        "    # SVC(gamma=2, C=1),\n",
        "    # GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    # DecisionTreeClassifier(max_depth=5),\n",
        "    # RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qu_s_yaapBk",
        "colab_type": "code",
        "outputId": "22f31084-a386-4824-dff3-db97c1542704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(f\"{name}: {f1_score(y_test, y_pred, average='micro')}\")\n",
        "    print(f\"{name}: {precision_score(y_test, y_pred, average='micro')}\")\n",
        "    print(f\"{name}: {recall_score(y_test, y_pred, average='micro')}\")\n",
        "    break"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear SVM: 0.06021775093266668\n",
            "Linear SVM: 0.0681866559909289\n",
            "Linear SVM: 0.05975088050525608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}